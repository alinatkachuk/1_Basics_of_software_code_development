{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinatkachuk/1_Basics_of_software_code_development/blob/master/homeworks/lab01_ml_pipeline/lab01_part2_ml_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-86e0de040aac317a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "jMKsXiswCG6L"
      },
      "source": [
        "# Lab assignment №1, part 2\n",
        "\n",
        "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
        "\n",
        "Several comments:\n",
        "* Don't hesitate to ask questions, it's a good practice.\n",
        "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
        "* Blocks of this lab will be graded separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QfH9SnDCG6P"
      },
      "source": [
        "__*This is the second part of the assignment. First and third parts are waiting for you in the same directory.*__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-512ba712fc0fc065",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "yy5pW8t_CG6Q"
      },
      "source": [
        "## Part 2. Data preprocessing, model training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b656a4266174b009",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "y0QuK5gsCG6Q"
      },
      "source": [
        "### 1. Reading the data\n",
        "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NpAvFzRCG6R",
        "outputId": "eeeb023a-ae7b-48f6-bf0f-6242d7e1f2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-15 15:08:33--  https://raw.githubusercontent.com/girafe-ai/ml-course/22f_made/homeworks/lab01_ml_pipeline/car_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58374 (57K) [text/plain]\n",
            "Saving to: ‘car_data.csv’\n",
            "\n",
            "\rcar_data.csv          0%[                    ]       0  --.-KB/s               \rcar_data.csv        100%[===================>]  57.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-15 15:08:33 (5.00 MB/s) - ‘car_data.csv’ saved [58374/58374]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# If on colab, uncomment the following lines\n",
        "\n",
        "! wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_made/homeworks/lab01_ml_pipeline/car_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eebac6bfdf73d0bc",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMZH_awoCG6S",
        "outputId": "160af142-d079-410b-a809-dd1cf2138031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(846, 19) (846,)\n",
            "(549, 19) (549,) (297, 19) (297,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
        "data = dataset[:, :-1].astype(int)\n",
        "target = dataset[:, -1]\n",
        "\n",
        "print(data.shape, target.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-88b1a0f688568f2c",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "Cv5Oe3ReCG6T"
      },
      "source": [
        "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "JYvS4V7-CG6T",
        "outputId": "ea1852e0-959e-49a9-af02-e71be5990799"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
              "0   725   91  37   76  138  55   8  132  51  18  135  157  256  124  69   0   \n",
              "1   803   93  47   84  205  71   7  176  36  21  152  190  476  201  70   7   \n",
              "2    85  110  58  106  180  51   6  261  26  28  171  278  998  257  83   9   \n",
              "3   671  103  41   83  194  63   9  175  38  21  142  199  455  138  65   7   \n",
              "4   179   89  44   70  137  58   6  136  49  18  146  168  273  166  78  10   \n",
              "5    18  104  54  100  186  61  10  216  31  24  173  225  686  220  74   5   \n",
              "6   340   89  40   72  155  63   7  146  45  19  135  175  321  145  72   4   \n",
              "7     7   90  43   66  157  65   9  137  48  18  146  162  281  164  67   3   \n",
              "8   167  110  51  104  191  57  12  213  31  24  162  226  674  190  68  18   \n",
              "9   503   91  39   72  133  55   7  146  46  19  132  170  314  149  77   9   \n",
              "10   99   87  44   65  124  56   6  149  46  19  144  170  321  171  87   4   \n",
              "11   24   99  53  105  219  66  11  204  32  23  165  221  623  224  68   0   \n",
              "12  399   87  42   64  150  64  10  133  50  18  141  157  265  159  67   7   \n",
              "13  792  100  51  104  163  52  10  206  32  23  164  217  631  193  69   5   \n",
              "14  708   94  49   82  137  56  10  159  43  20  160  176  367  186  76  10   \n",
              "\n",
              "    16   17   18  \n",
              "0   12  191  192  \n",
              "1   19  198  201  \n",
              "2   13  181  182  \n",
              "3   30  197  206  \n",
              "4    3  186  187  \n",
              "5   11  185  195  \n",
              "6   10  192  196  \n",
              "7    3  193  202  \n",
              "8    2  191  199  \n",
              "9   18  184  189  \n",
              "10  12  179  182  \n",
              "11   6  191  201  \n",
              "12   0  193  201  \n",
              "13  21  188  196  \n",
              "14   7  183  192  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e05e33a-5153-477a-a799-9a33042864d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>725</td>\n",
              "      <td>91</td>\n",
              "      <td>37</td>\n",
              "      <td>76</td>\n",
              "      <td>138</td>\n",
              "      <td>55</td>\n",
              "      <td>8</td>\n",
              "      <td>132</td>\n",
              "      <td>51</td>\n",
              "      <td>18</td>\n",
              "      <td>135</td>\n",
              "      <td>157</td>\n",
              "      <td>256</td>\n",
              "      <td>124</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>191</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>803</td>\n",
              "      <td>93</td>\n",
              "      <td>47</td>\n",
              "      <td>84</td>\n",
              "      <td>205</td>\n",
              "      <td>71</td>\n",
              "      <td>7</td>\n",
              "      <td>176</td>\n",
              "      <td>36</td>\n",
              "      <td>21</td>\n",
              "      <td>152</td>\n",
              "      <td>190</td>\n",
              "      <td>476</td>\n",
              "      <td>201</td>\n",
              "      <td>70</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>198</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85</td>\n",
              "      <td>110</td>\n",
              "      <td>58</td>\n",
              "      <td>106</td>\n",
              "      <td>180</td>\n",
              "      <td>51</td>\n",
              "      <td>6</td>\n",
              "      <td>261</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>171</td>\n",
              "      <td>278</td>\n",
              "      <td>998</td>\n",
              "      <td>257</td>\n",
              "      <td>83</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>181</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>671</td>\n",
              "      <td>103</td>\n",
              "      <td>41</td>\n",
              "      <td>83</td>\n",
              "      <td>194</td>\n",
              "      <td>63</td>\n",
              "      <td>9</td>\n",
              "      <td>175</td>\n",
              "      <td>38</td>\n",
              "      <td>21</td>\n",
              "      <td>142</td>\n",
              "      <td>199</td>\n",
              "      <td>455</td>\n",
              "      <td>138</td>\n",
              "      <td>65</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>197</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>179</td>\n",
              "      <td>89</td>\n",
              "      <td>44</td>\n",
              "      <td>70</td>\n",
              "      <td>137</td>\n",
              "      <td>58</td>\n",
              "      <td>6</td>\n",
              "      <td>136</td>\n",
              "      <td>49</td>\n",
              "      <td>18</td>\n",
              "      <td>146</td>\n",
              "      <td>168</td>\n",
              "      <td>273</td>\n",
              "      <td>166</td>\n",
              "      <td>78</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18</td>\n",
              "      <td>104</td>\n",
              "      <td>54</td>\n",
              "      <td>100</td>\n",
              "      <td>186</td>\n",
              "      <td>61</td>\n",
              "      <td>10</td>\n",
              "      <td>216</td>\n",
              "      <td>31</td>\n",
              "      <td>24</td>\n",
              "      <td>173</td>\n",
              "      <td>225</td>\n",
              "      <td>686</td>\n",
              "      <td>220</td>\n",
              "      <td>74</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>185</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>340</td>\n",
              "      <td>89</td>\n",
              "      <td>40</td>\n",
              "      <td>72</td>\n",
              "      <td>155</td>\n",
              "      <td>63</td>\n",
              "      <td>7</td>\n",
              "      <td>146</td>\n",
              "      <td>45</td>\n",
              "      <td>19</td>\n",
              "      <td>135</td>\n",
              "      <td>175</td>\n",
              "      <td>321</td>\n",
              "      <td>145</td>\n",
              "      <td>72</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>192</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>90</td>\n",
              "      <td>43</td>\n",
              "      <td>66</td>\n",
              "      <td>157</td>\n",
              "      <td>65</td>\n",
              "      <td>9</td>\n",
              "      <td>137</td>\n",
              "      <td>48</td>\n",
              "      <td>18</td>\n",
              "      <td>146</td>\n",
              "      <td>162</td>\n",
              "      <td>281</td>\n",
              "      <td>164</td>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>193</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>167</td>\n",
              "      <td>110</td>\n",
              "      <td>51</td>\n",
              "      <td>104</td>\n",
              "      <td>191</td>\n",
              "      <td>57</td>\n",
              "      <td>12</td>\n",
              "      <td>213</td>\n",
              "      <td>31</td>\n",
              "      <td>24</td>\n",
              "      <td>162</td>\n",
              "      <td>226</td>\n",
              "      <td>674</td>\n",
              "      <td>190</td>\n",
              "      <td>68</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>191</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>503</td>\n",
              "      <td>91</td>\n",
              "      <td>39</td>\n",
              "      <td>72</td>\n",
              "      <td>133</td>\n",
              "      <td>55</td>\n",
              "      <td>7</td>\n",
              "      <td>146</td>\n",
              "      <td>46</td>\n",
              "      <td>19</td>\n",
              "      <td>132</td>\n",
              "      <td>170</td>\n",
              "      <td>314</td>\n",
              "      <td>149</td>\n",
              "      <td>77</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>184</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>99</td>\n",
              "      <td>87</td>\n",
              "      <td>44</td>\n",
              "      <td>65</td>\n",
              "      <td>124</td>\n",
              "      <td>56</td>\n",
              "      <td>6</td>\n",
              "      <td>149</td>\n",
              "      <td>46</td>\n",
              "      <td>19</td>\n",
              "      <td>144</td>\n",
              "      <td>170</td>\n",
              "      <td>321</td>\n",
              "      <td>171</td>\n",
              "      <td>87</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>179</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24</td>\n",
              "      <td>99</td>\n",
              "      <td>53</td>\n",
              "      <td>105</td>\n",
              "      <td>219</td>\n",
              "      <td>66</td>\n",
              "      <td>11</td>\n",
              "      <td>204</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>165</td>\n",
              "      <td>221</td>\n",
              "      <td>623</td>\n",
              "      <td>224</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>191</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>399</td>\n",
              "      <td>87</td>\n",
              "      <td>42</td>\n",
              "      <td>64</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>10</td>\n",
              "      <td>133</td>\n",
              "      <td>50</td>\n",
              "      <td>18</td>\n",
              "      <td>141</td>\n",
              "      <td>157</td>\n",
              "      <td>265</td>\n",
              "      <td>159</td>\n",
              "      <td>67</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>193</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>792</td>\n",
              "      <td>100</td>\n",
              "      <td>51</td>\n",
              "      <td>104</td>\n",
              "      <td>163</td>\n",
              "      <td>52</td>\n",
              "      <td>10</td>\n",
              "      <td>206</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>164</td>\n",
              "      <td>217</td>\n",
              "      <td>631</td>\n",
              "      <td>193</td>\n",
              "      <td>69</td>\n",
              "      <td>5</td>\n",
              "      <td>21</td>\n",
              "      <td>188</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>708</td>\n",
              "      <td>94</td>\n",
              "      <td>49</td>\n",
              "      <td>82</td>\n",
              "      <td>137</td>\n",
              "      <td>56</td>\n",
              "      <td>10</td>\n",
              "      <td>159</td>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>160</td>\n",
              "      <td>176</td>\n",
              "      <td>367</td>\n",
              "      <td>186</td>\n",
              "      <td>76</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>183</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e05e33a-5153-477a-a799-9a33042864d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e05e33a-5153-477a-a799-9a33042864d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e05e33a-5153-477a-a799-9a33042864d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c0759d68-85bb-4b50-a748-4892db79680c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0759d68-85bb-4b50-a748-4892db79680c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c0759d68-85bb-4b50-a748-4892db79680c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_pd",
              "summary": "{\n  \"name\": \"X_train_pd\",\n  \"rows\": 549,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 246,\n        \"min\": 0,\n        \"max\": 845,\n        \"num_unique_values\": 549,\n        \"samples\": [\n          820,\n          297,\n          217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 73,\n        \"max\": 119,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          76,\n          108,\n          86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 33,\n        \"max\": 59,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          51,\n          57,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 40,\n        \"max\": 110,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          76,\n          100,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 104,\n        \"max\": 322,\n        \"num_unique_values\": 131,\n        \"samples\": [\n          217,\n          188,\n          120\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 47,\n        \"max\": 133,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          76,\n          54,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2,\n        \"max\": 55,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          8,\n          7,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 112,\n        \"max\": 262,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          147,\n          227,\n          136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 26,\n        \"max\": 61,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          53,\n          27,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 17,\n        \"max\": 28,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          27,\n          22,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 118,\n        \"max\": 188,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          122,\n          153,\n          135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 130,\n        \"max\": 285,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          188,\n          168,\n          143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174,\n        \"min\": 184,\n        \"max\": 998,\n        \"num_unique_values\": 345,\n        \"samples\": [\n          452,\n          371,\n          670\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 13,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 109,\n        \"max\": 264,\n        \"num_unique_values\": 137,\n        \"samples\": [\n          262,\n          249,\n          159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 14,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 59,\n        \"max\": 127,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          84,\n          81,\n          79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 15,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 22,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          11,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 16,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 41,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          24,\n          8,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 17,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 176,\n        \"max\": 206,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          202,\n          195,\n          206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 18,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 181,\n        \"max\": 211,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          186,\n          205,\n          193\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X_train_pd = pd.DataFrame(X_train)\n",
        "\n",
        "# First 15 rows of our dataset.\n",
        "X_train_pd.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-98e7d91d77d65fcf",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "9wAYDmY0CG6U"
      },
      "source": [
        "Methods `describe` and `info` deliver some useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOGCBl-YCG6U",
        "outputId": "33939ce6-3b52-4348-a6d9-f23cfc422011"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>549.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>432.114754</td>\n",
              "      <td>93.839709</td>\n",
              "      <td>44.765027</td>\n",
              "      <td>81.872495</td>\n",
              "      <td>169.358834</td>\n",
              "      <td>61.817851</td>\n",
              "      <td>8.433515</td>\n",
              "      <td>168.934426</td>\n",
              "      <td>40.865209</td>\n",
              "      <td>20.588342</td>\n",
              "      <td>147.571949</td>\n",
              "      <td>188.744991</td>\n",
              "      <td>440.672131</td>\n",
              "      <td>174.539162</td>\n",
              "      <td>72.449909</td>\n",
              "      <td>6.557377</td>\n",
              "      <td>12.568306</td>\n",
              "      <td>189.030965</td>\n",
              "      <td>195.491803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>240.666501</td>\n",
              "      <td>8.335779</td>\n",
              "      <td>6.190806</td>\n",
              "      <td>15.647408</td>\n",
              "      <td>32.834864</td>\n",
              "      <td>7.971412</td>\n",
              "      <td>4.491440</td>\n",
              "      <td>33.163102</td>\n",
              "      <td>7.790602</td>\n",
              "      <td>2.588917</td>\n",
              "      <td>14.451808</td>\n",
              "      <td>31.241299</td>\n",
              "      <td>176.701194</td>\n",
              "      <td>32.845869</td>\n",
              "      <td>7.308114</td>\n",
              "      <td>5.006099</td>\n",
              "      <td>9.010809</td>\n",
              "      <td>6.200788</td>\n",
              "      <td>7.435024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>177.000000</td>\n",
              "      <td>181.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>225.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>319.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>190.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>431.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>367.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>197.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>644.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>575.000000</td>\n",
              "      <td>198.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>193.000000</td>\n",
              "      <td>201.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>845.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>322.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>265.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>287.000000</td>\n",
              "      <td>1018.000000</td>\n",
              "      <td>268.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>211.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2           3           4           5   \\\n",
              "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
              "mean   432.114754   93.839709   44.765027   81.872495  169.358834   61.817851   \n",
              "std    240.666501    8.335779    6.190806   15.647408   32.834864    7.971412   \n",
              "min      0.000000   77.000000   33.000000   40.000000  104.000000   47.000000   \n",
              "25%    225.000000   87.000000   40.000000   70.000000  142.000000   57.000000   \n",
              "50%    431.000000   93.000000   44.000000   79.000000  169.000000   61.000000   \n",
              "75%    644.000000  100.000000   49.000000   96.000000  195.000000   65.000000   \n",
              "max    845.000000  119.000000   59.000000  112.000000  322.000000  133.000000   \n",
              "\n",
              "               6           7           8           9           10          11  \\\n",
              "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
              "mean     8.433515  168.934426   40.865209   20.588342  147.571949  188.744991   \n",
              "std      4.491440   33.163102    7.790602    2.588917   14.451808   31.241299   \n",
              "min      3.000000  112.000000   26.000000   17.000000  118.000000  130.000000   \n",
              "25%      6.000000  147.000000   34.000000   19.000000  136.000000  167.000000   \n",
              "50%      8.000000  157.000000   43.000000   20.000000  146.000000  179.000000   \n",
              "75%     10.000000  195.000000   46.000000   22.000000  159.000000  216.000000   \n",
              "max     52.000000  265.000000   61.000000   29.000000  186.000000  287.000000   \n",
              "\n",
              "                12          13          14          15          16  \\\n",
              "count   549.000000  549.000000  549.000000  549.000000  549.000000   \n",
              "mean    440.672131  174.539162   72.449909    6.557377   12.568306   \n",
              "std     176.701194   32.845869    7.308114    5.006099    9.010809   \n",
              "min     184.000000  109.000000   60.000000    0.000000    0.000000   \n",
              "25%     319.000000  149.000000   67.000000    2.000000    5.000000   \n",
              "50%     367.000000  174.000000   71.000000    6.000000   11.000000   \n",
              "75%     575.000000  198.000000   75.000000   10.000000   19.000000   \n",
              "max    1018.000000  268.000000  127.000000   22.000000   41.000000   \n",
              "\n",
              "               17          18  \n",
              "count  549.000000  549.000000  \n",
              "mean   189.030965  195.491803  \n",
              "std      6.200788    7.435024  \n",
              "min    177.000000  181.000000  \n",
              "25%    184.000000  190.000000  \n",
              "50%    189.000000  197.000000  \n",
              "75%    193.000000  201.000000  \n",
              "max    206.000000  211.000000  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_pd.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaPy2zB2CG6U",
        "outputId": "bd573898-00d4-4b69-8ad0-927ecf40b735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 549 entries, 0 to 548\n",
            "Data columns (total 19 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       549 non-null    int64\n",
            " 1   1       549 non-null    int64\n",
            " 2   2       549 non-null    int64\n",
            " 3   3       549 non-null    int64\n",
            " 4   4       549 non-null    int64\n",
            " 5   5       549 non-null    int64\n",
            " 6   6       549 non-null    int64\n",
            " 7   7       549 non-null    int64\n",
            " 8   8       549 non-null    int64\n",
            " 9   9       549 non-null    int64\n",
            " 10  10      549 non-null    int64\n",
            " 11  11      549 non-null    int64\n",
            " 12  12      549 non-null    int64\n",
            " 13  13      549 non-null    int64\n",
            " 14  14      549 non-null    int64\n",
            " 15  15      549 non-null    int64\n",
            " 16  16      549 non-null    int64\n",
            " 17  17      549 non-null    int64\n",
            " 18  18      549 non-null    int64\n",
            "dtypes: int64(19)\n",
            "memory usage: 81.6 KB\n"
          ]
        }
      ],
      "source": [
        "X_train_pd.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-be844269be69c387",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "DK8ToeWyCG6V"
      },
      "source": [
        "### 2. Machine Learning pipeline\n",
        "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY4QInW8CG6V"
      },
      "source": [
        "#### 2.0. Data preprocessing\n",
        "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-a1514aa189a49fca",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luvoRbVzCG6V",
        "outputId": "ab0a8a18-1ca0-4fc5-9c29-2d7da850f975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: (549, 19)\n",
            "Test data: (297, 19)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Processing of outliers by 6 feature (max=52 at 75% percentile=10)\n",
        "def cap_outliers(X, lower_percentile=1, upper_percentile=99):\n",
        "    X_capped = X.copy()\n",
        "    for i in range(X.shape[1]):\n",
        "        lower_bound = np.percentile(X[:, i], lower_percentile)\n",
        "        upper_bound = np.percentile(X[:, i], upper_percentile)\n",
        "        X_capped[:, i] = np.clip(X[:, i], lower_bound, upper_bound)\n",
        "    return X_capped\n",
        "\n",
        "# Process outliers only in problematic features\n",
        "problem_features = [6]  # Index of the problematic feature\n",
        "\n",
        "X_train_processed = X_train.copy()\n",
        "X_test_processed = X_test.copy()\n",
        "\n",
        "for feature_idx in problem_features:\n",
        "    lower_bound = np.percentile(X_train[:, feature_idx], 1)\n",
        "    upper_bound = np.percentile(X_train[:, feature_idx], 99)\n",
        "\n",
        "    X_train_processed[:, feature_idx] = np.clip(X_train[:, feature_idx], lower_bound, upper_bound)\n",
        "    X_test_processed[:, feature_idx] = np.clip(X_test[:, feature_idx], lower_bound, upper_bound)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_final = scaler.fit_transform(X_train_processed)\n",
        "X_test_final = scaler.transform(X_test_processed)\n",
        "\n",
        "print(f\"Training data: {X_train_final.shape}\")\n",
        "print(f\"Test data: {X_test_final.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUCAMtmxCG6V"
      },
      "source": [
        "#### 2.1. Basic logistic regression\n",
        "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
        "\n",
        "* Estimate the model quality with `f1` and `accuracy` scores.\n",
        "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
        "\n",
        "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-1dd5ad5d0845cbbb",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        },
        "id": "0kWmxXjkCG6V"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iul8bDyeCG6V"
      },
      "outputs": [],
      "source": [
        "# You might use this command to install scikit-plot.\n",
        "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding\n",
        "# virtual environment instead\n",
        "\n",
        "# ! pip install scikit-plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUt3Wh90CG6W"
      },
      "source": [
        "#### 2.2. PCA: explained variance plot\n",
        "* Apply the PCA to the train part of the data. Build the explaided variance plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-c6c614740bce090e",
          "locked": false,
          "points": 10,
          "schema_version": 2,
          "solution": true
        },
        "id": "u28BsxysCG6W"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0c1fe666f52fe53c",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "x_b0iGnhCG6W"
      },
      "source": [
        "#### 2.3. PCA trasformation\n",
        "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
        "\n",
        "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-96ab18d96473ef71",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        },
        "id": "3iKagPCdCG6W"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7naIdmYCCG6W"
      },
      "source": [
        "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d28b58a35c94e988",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "EjvQYRq5CG6W"
      },
      "source": [
        "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
        "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
        "\n",
        "* Estimate the model quality with `f1` and `accuracy` scores.\n",
        "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
        "\n",
        "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-12d53ea45258fa82",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        },
        "id": "vyRhhmSmCG6W"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4fbf16c64076e139",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "to-GLcJ_CG6X"
      },
      "source": [
        "#### 2.5. Decision tree\n",
        "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n",
        "\n",
        "* Measure the model quality using the same metrics you used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-748ed20b51c67fab",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "id": "8z0qv95GCG6X"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9eadd4d8a03ae67a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "2M8rIrD-CG6X"
      },
      "source": [
        "#### 2.6. Bagging.\n",
        "Here starts the ensembling part.\n",
        "\n",
        "First we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n",
        "\n",
        "We will build two ensembles: of logistic regressions and of decision trees.\n",
        "\n",
        "*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n",
        "\n",
        "\n",
        "*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n",
        "\n",
        "*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n",
        "\n",
        "* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n",
        "\n",
        "* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n",
        "\n",
        "* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-8fc95a2b206bdae1",
          "locked": false,
          "points": 35,
          "schema_version": 2,
          "solution": true
        },
        "id": "RhBCvnn6CG6X"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAM1kevDCG6X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-241b7691ab44cbfb",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "9dXe28Q1CG6X"
      },
      "source": [
        "#### 2.7. Random Forest\n",
        "Now we will work with the Random Forest (its `sklearn` implementation).\n",
        "\n",
        "* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n",
        "\n",
        "* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-888755d0f3d91620",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "id": "yxDg3_ADCG6X"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-99191c0852538d4d",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "8-29fb84CG6X"
      },
      "source": [
        "#### 2.8. Learning curve\n",
        "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
        "\n",
        "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
        "\n",
        "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
        "\n",
        "* Analyse the final plot. Can you make any conlusions using it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-e39bc7e7dff61ff9",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "id": "Du3GPdbpCG6Y"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S17HVar8CG6Y"
      },
      "source": [
        "#### 2.9. Boosting\n",
        "Your goal is to build a boosting ensemble using xgboost, CatBoost or lightgbm package.\n",
        "Please, do not use the sklearn API for these models.\n",
        "\n",
        "Find optimal number of decision trees in the boosting ensembe using grid search or other methods.\n",
        "Please, explain your answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWyEiknMCG6Y"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}